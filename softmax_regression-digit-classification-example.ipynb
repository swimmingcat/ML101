{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0a9640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e97bf4",
   "metadata": {},
   "source": [
    "Wine data set\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11689ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits(as_frame=True)\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a1c93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f731f066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303840</td>\n",
       "      <td>5.204786</td>\n",
       "      <td>11.835838</td>\n",
       "      <td>11.848080</td>\n",
       "      <td>5.781859</td>\n",
       "      <td>1.362270</td>\n",
       "      <td>0.129661</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725097</td>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>5.557596</td>\n",
       "      <td>12.089037</td>\n",
       "      <td>11.809126</td>\n",
       "      <td>6.764051</td>\n",
       "      <td>2.067891</td>\n",
       "      <td>0.364496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907192</td>\n",
       "      <td>4.754826</td>\n",
       "      <td>4.248842</td>\n",
       "      <td>4.287388</td>\n",
       "      <td>5.666418</td>\n",
       "      <td>3.325775</td>\n",
       "      <td>1.037383</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>3.196160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.919406</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.934302</td>\n",
       "      <td>5.103019</td>\n",
       "      <td>4.374694</td>\n",
       "      <td>4.933947</td>\n",
       "      <td>5.900623</td>\n",
       "      <td>4.090548</td>\n",
       "      <td>1.860122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
       "count     1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean         0.0     0.303840     5.204786    11.835838    11.848080   \n",
       "std          0.0     0.907192     4.754826     4.248842     4.287388   \n",
       "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
       "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
       "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
       "\n",
       "         pixel_6_6    pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
       "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
       "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
       "\n",
       "         pixel_7_3    pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7  \n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
       "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
       "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
       "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
       "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a0e92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 72x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.figure(figsize=(1, 1))\n",
    "plt.matshow(digits.images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8467722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2c3dd",
   "metadata": {},
   "source": [
    "# Softmax Regression With SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe2b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    tol=1e-4,\n",
    "    solver='newton-cg',\n",
    "    max_iter=1000,\n",
    "    verbose=1,\n",
    "    penalty='l2'\n",
    ").fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd55da96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 0.034208230618038155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import math\n",
    "\n",
    "y_prob = lr_model.predict_proba(X)\n",
    "mlogloss = log_loss(y, y_prob)\n",
    "\n",
    "print(\"Logloss: {}\".format(mlogloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b2b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "CATEGORIES = list(range(0, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1cbfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "196b6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        33\n",
      "           1     0.9655    1.0000    0.9825        28\n",
      "           2     0.9706    1.0000    0.9851        33\n",
      "           3     0.9706    0.9706    0.9706        34\n",
      "           4     1.0000    0.9783    0.9890        46\n",
      "           5     0.9167    0.9362    0.9263        47\n",
      "           6     0.9714    0.9714    0.9714        35\n",
      "           7     1.0000    0.9706    0.9851        34\n",
      "           8     0.9667    0.9667    0.9667        30\n",
      "           9     0.9744    0.9500    0.9620        40\n",
      "\n",
      "    accuracy                         0.9722       360\n",
      "   macro avg     0.9736    0.9744    0.9739       360\n",
      "weighted avg     0.9726    0.9722    0.9723       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_validation, y_pred=y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09ddce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_validation, y_pred=y_hat, labels=CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "797c86d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 28,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 33,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 33,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 45,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0, 44,  1,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  1, 34,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0, 33,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0, 29,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  1, 38]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fde6c",
   "metadata": {},
   "source": [
    "# Gradient Boost Tree with Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea733131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'multi:softmax', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': None, 'colsample_bynode': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'gpu_id': None, 'interaction_constraints': None, 'learning_rate': 0.3, 'max_delta_step': None, 'max_depth': 5, 'min_child_weight': 1, 'monotone_constraints': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': 'hist', 'validate_parameters': None, 'verbosity': 1, 'num_class': 10, 'seed': 1234}\n",
      "[0]\tvalidation_0-merror:0.06889\tvalidation_0-mlogloss:1.30873\tvalidation_1-merror:0.13056\tvalidation_1-mlogloss:1.37365\n",
      "[1]\tvalidation_0-merror:0.03340\tvalidation_0-mlogloss:0.94138\tvalidation_1-merror:0.09722\tvalidation_1-mlogloss:1.04528\n",
      "[2]\tvalidation_0-merror:0.02018\tvalidation_0-mlogloss:0.71044\tvalidation_1-merror:0.07500\tvalidation_1-mlogloss:0.82738\n",
      "[3]\tvalidation_0-merror:0.01113\tvalidation_0-mlogloss:0.54289\tvalidation_1-merror:0.06111\tvalidation_1-mlogloss:0.66495\n",
      "[4]\tvalidation_0-merror:0.00835\tvalidation_0-mlogloss:0.42522\tvalidation_1-merror:0.05278\tvalidation_1-mlogloss:0.55544\n",
      "[5]\tvalidation_0-merror:0.00626\tvalidation_0-mlogloss:0.33546\tvalidation_1-merror:0.05000\tvalidation_1-mlogloss:0.46970\n",
      "[6]\tvalidation_0-merror:0.00487\tvalidation_0-mlogloss:0.26693\tvalidation_1-merror:0.05556\tvalidation_1-mlogloss:0.40068\n",
      "[7]\tvalidation_0-merror:0.00348\tvalidation_0-mlogloss:0.21682\tvalidation_1-merror:0.04722\tvalidation_1-mlogloss:0.35232\n",
      "[8]\tvalidation_0-merror:0.00278\tvalidation_0-mlogloss:0.17618\tvalidation_1-merror:0.04444\tvalidation_1-mlogloss:0.30632\n",
      "[9]\tvalidation_0-merror:0.00209\tvalidation_0-mlogloss:0.14303\tvalidation_1-merror:0.04722\tvalidation_1-mlogloss:0.26876\n",
      "[10]\tvalidation_0-merror:0.00209\tvalidation_0-mlogloss:0.11833\tvalidation_1-merror:0.04444\tvalidation_1-mlogloss:0.24169\n",
      "[11]\tvalidation_0-merror:0.00070\tvalidation_0-mlogloss:0.09846\tvalidation_1-merror:0.04444\tvalidation_1-mlogloss:0.21683\n",
      "[12]\tvalidation_0-merror:0.00070\tvalidation_0-mlogloss:0.08261\tvalidation_1-merror:0.04167\tvalidation_1-mlogloss:0.19832\n",
      "[13]\tvalidation_0-merror:0.00070\tvalidation_0-mlogloss:0.07027\tvalidation_1-merror:0.04167\tvalidation_1-mlogloss:0.18425\n",
      "[14]\tvalidation_0-merror:0.00070\tvalidation_0-mlogloss:0.06024\tvalidation_1-merror:0.04167\tvalidation_1-mlogloss:0.17172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lzhao/opt/miniconda3/envs/ml_dev2/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.05237\tvalidation_1-merror:0.04167\tvalidation_1-mlogloss:0.16196\n",
      "[16]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.04555\tvalidation_1-merror:0.04444\tvalidation_1-mlogloss:0.15194\n",
      "[17]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.03985\tvalidation_1-merror:0.03889\tvalidation_1-mlogloss:0.14387\n",
      "[18]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.03517\tvalidation_1-merror:0.03889\tvalidation_1-mlogloss:0.13788\n",
      "[19]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.03151\tvalidation_1-merror:0.03889\tvalidation_1-mlogloss:0.13294\n",
      "[20]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.02849\tvalidation_1-merror:0.03611\tvalidation_1-mlogloss:0.12778\n",
      "[21]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.02593\tvalidation_1-merror:0.03333\tvalidation_1-mlogloss:0.12468\n",
      "[22]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.02373\tvalidation_1-merror:0.03333\tvalidation_1-mlogloss:0.12058\n",
      "[23]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.02179\tvalidation_1-merror:0.03333\tvalidation_1-mlogloss:0.11593\n",
      "[24]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.02023\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.11390\n",
      "[25]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01877\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.11066\n",
      "[26]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01753\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.10849\n",
      "[27]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01634\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.10657\n",
      "[28]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01540\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.10376\n",
      "[29]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01460\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.10149\n",
      "[30]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01378\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.09981\n",
      "[31]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01311\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.09873\n",
      "[32]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01250\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.09674\n",
      "[33]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01195\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.09620\n",
      "[34]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01147\tvalidation_1-merror:0.02778\tvalidation_1-mlogloss:0.09463\n",
      "[35]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01102\tvalidation_1-merror:0.03056\tvalidation_1-mlogloss:0.09360\n",
      "[36]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01064\tvalidation_1-merror:0.02778\tvalidation_1-mlogloss:0.09308\n",
      "[37]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.01027\tvalidation_1-merror:0.02778\tvalidation_1-mlogloss:0.09277\n",
      "[38]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00989\tvalidation_1-merror:0.02778\tvalidation_1-mlogloss:0.09233\n",
      "[39]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00960\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.09175\n",
      "[40]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00933\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.09180\n",
      "[41]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00909\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.09073\n",
      "[42]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00887\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.09019\n",
      "[43]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00864\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08943\n",
      "[44]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00842\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08826\n",
      "[45]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00825\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08788\n",
      "[46]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00808\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08762\n",
      "[47]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00790\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08733\n",
      "[48]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00776\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08662\n",
      "[49]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00762\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08631\n",
      "[50]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00749\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08580\n",
      "[51]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00735\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08557\n",
      "[52]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00722\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08545\n",
      "[53]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00711\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08498\n",
      "[54]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00699\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08443\n",
      "[55]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00688\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08459\n",
      "[56]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00677\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08455\n",
      "[57]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00666\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08452\n",
      "[58]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00657\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08442\n",
      "[59]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00649\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08419\n",
      "[60]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00639\tvalidation_1-merror:0.02500\tvalidation_1-mlogloss:0.08389\n",
      "[61]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00632\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08393\n",
      "[62]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00623\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08361\n",
      "[63]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00617\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08360\n",
      "[64]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00611\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08362\n",
      "[65]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00605\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08335\n",
      "[66]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00600\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08322\n",
      "[67]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00594\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08312\n",
      "[68]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00589\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08317\n",
      "[69]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00583\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08263\n",
      "[70]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00579\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08249\n",
      "[71]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00574\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08256\n",
      "[72]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00569\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08268\n",
      "[73]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00564\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08252\n",
      "[74]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00559\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08254\n",
      "[75]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00555\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08204\n",
      "[76]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00551\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08207\n",
      "[77]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00547\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08198\n",
      "[78]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00543\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08185\n",
      "[79]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00540\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08209\n",
      "[80]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00537\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08209\n",
      "[81]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00534\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08222\n",
      "[82]\tvalidation_0-merror:0.00000\tvalidation_0-mlogloss:0.00530\tvalidation_1-merror:0.02222\tvalidation_1-mlogloss:0.08228\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "my_model = XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    objective='multi:softmax',\n",
    "    num_class=10,\n",
    "    \n",
    "    gamma=0,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.3, \n",
    "    min_child_weight=1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "\n",
    "    random_state=0,\n",
    "    booster='gbtree',\n",
    "    tree_method='hist',\n",
    "    seed=1234,\n",
    "    missing=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "print(my_model.get_xgb_params())\n",
    "\n",
    "trained = my_model.fit(\n",
    "    X_train, y_train, early_stopping_rounds=5,\n",
    "    # the last metric is used for early stopping\n",
    "    eval_metric=[\"merror\", \"mlogloss\"],\n",
    "    eval_set=[(X_train, y_train), (X_validation, y_validation)], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf056989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        33\n",
      "           1     1.0000    1.0000    1.0000        28\n",
      "           2     0.9706    1.0000    0.9851        33\n",
      "           3     1.0000    0.9706    0.9851        34\n",
      "           4     1.0000    1.0000    1.0000        46\n",
      "           5     0.9574    0.9574    0.9574        47\n",
      "           6     0.9714    0.9714    0.9714        35\n",
      "           7     0.9429    0.9706    0.9565        34\n",
      "           8     1.0000    0.9667    0.9831        30\n",
      "           9     0.9500    0.9500    0.9500        40\n",
      "\n",
      "    accuracy                         0.9778       360\n",
      "   macro avg     0.9792    0.9787    0.9789       360\n",
      "weighted avg     0.9780    0.9778    0.9778       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = trained.predict(X_validation)\n",
    "print(classification_report(y_true=y_validation, y_pred=y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e99eddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 28,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 33,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 33,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 46,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 45,  1,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  1, 34,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  1],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0, 29,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  0, 38]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_validation, y_pred=y_hat, labels=CATEGORIES)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c42597",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd3cf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, History, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Input, Reshape, Dense, Conv2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, SparseCategoricalCrossentropy, SparseCategoricalAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c34ded17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    inputs = Input(shape=(64,))\n",
    "    l = inputs\n",
    "    \n",
    "    l = Reshape((8,8,1), name='reshape')(l)\n",
    "    l = Conv2D(\n",
    "        filters=16,kernel_size=[3,3],\n",
    "        padding='same',activation='relu', name='conv1')(l)\n",
    "    l = BatchNormalization()(l)\n",
    "    l = Dropout(0.2)(l)\n",
    "\n",
    "    \n",
    "    l = Conv2D(\n",
    "        filters=4,kernel_size=[3,3],\n",
    "        padding='same',activation='relu', name='conv2')(l)\n",
    "    l = BatchNormalization()(l)\n",
    "\n",
    "    \n",
    "    l = Reshape((4*8*8,), name='flatten')(l)\n",
    "    l = Dense(10, activation=\"softmax\", name='main_output')(l)\n",
    "\n",
    "\n",
    "    m_cnn = Model(inputs=inputs, outputs=l)\n",
    "    print(m_cnn.summary())\n",
    "    return m_cnn\n",
    "\n",
    "def model_train(X_train, y_train, X_val, y_val, model):\n",
    "    print(model.summary())\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\", min_delta=1e-5, patience=3,\n",
    "        verbose=0, mode=\"auto\", baseline=None, restore_best_weights=True\n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=1, min_lr=1e-4)\n",
    "\n",
    "    callbacks_list = [early_stop, reduce_lr]\n",
    "\n",
    "    # optimizer: gradient descent implementation\n",
    "    adam_wn = Adam(learning_rate=0.1)\n",
    "    \n",
    "    # compile model with loss and optimizer; loss function needs to match the intention and the output of the last layer\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=adam_wn,\n",
    "        metrics=[SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # kick off model training\n",
    "    return model.fit(\n",
    "        x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=16,\n",
    "        epochs=1000, verbose=1, shuffle=True,\n",
    "        callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ad9ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2f44c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7544b2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 8, 8, 16)          160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 8, 8, 4)           580       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 4)           16        \n",
      "_________________________________________________________________\n",
      "flatten (Reshape)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,390\n",
      "Trainable params: 3,350\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 8, 8, 16)          160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 8, 8, 4)           580       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 4)           16        \n",
      "_________________________________________________________________\n",
      "flatten (Reshape)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,390\n",
      "Trainable params: 3,350\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "90/90 [==============================] - 1s 4ms/step - loss: 0.5688 - sparse_categorical_accuracy: 0.8615 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.9222\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1653 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9583\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.1756 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.1508 - val_sparse_categorical_accuracy: 0.9694\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9694\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.1509 - val_sparse_categorical_accuracy: 0.9722\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.2014 - val_sparse_categorical_accuracy: 0.9528\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0586 - val_sparse_categorical_accuracy: 0.9861\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0366 - val_sparse_categorical_accuracy: 0.9917\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9861\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9833\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8070875c50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_tf_model = build_cnn()\n",
    "\n",
    "model_train(X_train_scaled, y_train, X_validation_scaled, y_validation, my_tf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac25d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        33\n",
      "           1     1.0000    1.0000    1.0000        28\n",
      "           2     1.0000    1.0000    1.0000        33\n",
      "           3     1.0000    0.9706    0.9851        34\n",
      "           4     1.0000    1.0000    1.0000        46\n",
      "           5     0.9787    0.9787    0.9787        47\n",
      "           6     0.9722    1.0000    0.9859        35\n",
      "           7     1.0000    0.9706    0.9851        34\n",
      "           8     1.0000    1.0000    1.0000        30\n",
      "           9     0.9756    1.0000    0.9877        40\n",
      "\n",
      "    accuracy                         0.9917       360\n",
      "   macro avg     0.9927    0.9920    0.9922       360\n",
      "weighted avg     0.9918    0.9917    0.9917       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_hat = np.argmax(my_tf_model.predict(X_validation_scaled), axis=1)\n",
    "print(classification_report(y_true=y_validation, y_pred=y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d736e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 28,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 33,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 33,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 46,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 46,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 35,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 30,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=y_validation, y_pred=y_hat, labels=CATEGORIES)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df0188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
